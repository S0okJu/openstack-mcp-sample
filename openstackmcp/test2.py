#!/usr/bin/env python3
"""
OpenStack MCP Class-Based Server
í´ë˜ìŠ¤ ê¸°ë°˜ êµ¬ì¡°í™”ëœ OpenStack MCP ì„œë²„
"""

import json
import os
import re
from typing import Dict, Any, List, Optional
from datetime import datetime

import openstack
from openstack import connection
from fastmcp import FastMCP, Context


class OpenStackMCP:
    """OpenStack MCP Server í´ë˜ìŠ¤"""
    
    def __init__(self, name: str = 'openstack-mcp'):
        """
        OpenStack MCP ì„œë²„ ì´ˆê¸°í™”
        
        Args:
            name: MCP ì„œë²„ ì´ë¦„
        """
        self.server = FastMCP(name)  # name=mcp ì˜¤íƒ€ ìˆ˜ì •
        self.conn = self._connect_openstack()
        self._setup_tools()
        
    def _connect_openstack(self) -> connection.Connection:
        """OpenStack ì—°ê²° ì„¤ì •"""
        try:
            # í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•œ ì—°ê²°
            if all(key in os.environ for key in ['OS_AUTH_URL', 'OS_USERNAME', 'OS_PASSWORD', 'OS_PROJECT_NAME']):
                conn = openstack.connect(
                    auth_url=os.environ['OS_AUTH_URL'],
                    project_name=os.environ['OS_PROJECT_NAME'],
                    username=os.environ['OS_USERNAME'],
                    password=os.environ['OS_PASSWORD'],
                    user_domain_name=os.environ.get('OS_USER_DOMAIN_NAME', 'Default'),
                    project_domain_name=os.environ.get('OS_PROJECT_DOMAIN_NAME', 'Default'),
                    region_name=os.environ.get('OS_REGION_NAME', 'RegionOne'),
                    interface=os.environ.get('OS_INTERFACE', 'public'),
                    identity_api_version=os.environ.get('OS_IDENTITY_API_VERSION', '3')
                )
            else:
                # clouds.yamlì„ í†µí•œ ì—°ê²°
                conn = openstack.connect(cloud=os.environ.get('OS_CLOUD', 'openstack'))
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            conn.authorize()
            print("âœ… OpenStack connection established successfully")
            return conn
            
        except Exception as e:
            print(f"âŒ Failed to connect to OpenStack: {e}")
            raise
    
    def _setup_tools(self):
        """ëª¨ë“  MCP íˆ´ë“¤ì„ ë“±ë¡"""
        
        # Nova (Compute) ê´€ë ¨ íˆ´ë“¤
        @self.server.tool()
        def nova_list(detailed: bool = False, status: Optional[str] = None) -> str:
            """
            Nova ì„œë²„ ëª©ë¡ ì¡°íšŒ
            
            Args:
                detailed: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
                status: ìƒíƒœë³„ í•„í„°ë§ (ACTIVE, SHUTOFF, ERROR ë“±)
            """
            return self.nova_list_impl(detailed, status)
        
        @self.server.tool()
        def nova_show(server_id: str) -> str:
            """
            íŠ¹ì • ì„œë²„ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
            
            Args:
                server_id: ì„œë²„ ID ë˜ëŠ” ì´ë¦„
            """
            return self.nova_show_impl(server_id)
        
        @self.server.tool()
        def nova_console_log(server_id: str, length: int = 50) -> str:
            """
            ì„œë²„ ì½˜ì†” ë¡œê·¸ ì¡°íšŒ
            
            Args:
                server_id: ì„œë²„ ID ë˜ëŠ” ì´ë¦„
                length: ì¡°íšŒí•  ë¼ì¸ ìˆ˜
            """
            return self.nova_console_log_impl(server_id, length)
        
        # AI ë¶„ì„ ê´€ë ¨ íˆ´ë“¤
        @self.server.tool()
        async def analyze_instance_errors(server_id: str, ctx: Context, log_lines: int = 200) -> str:
            """
            AIë¥¼ í™œìš©í•œ ì¸ìŠ¤í„´ìŠ¤ ì—ëŸ¬ ë¶„ì„
            
            Args:
                server_id: ì„œë²„ ID ë˜ëŠ” ì´ë¦„
                ctx: FastMCP Context
                log_lines: ë¶„ì„í•  ë¡œê·¸ ë¼ì¸ ìˆ˜
            """
            return await self.analyze_instance_errors_impl(server_id, log_lines, ctx)
        
        @self.server.tool()
        async def bulk_infrastructure_analysis(ctx: Context,
                                             status_filter: Optional[str] = None, 
                                             max_instances: int = 10) -> str:
            """
            ì¸í”„ë¼ ì „ì²´ ì¼ê´„ ë¶„ì„
            
            Args:
                ctx: FastMCP Context
                status_filter: ìƒíƒœë³„ í•„í„°ë§
                max_instances: ë¶„ì„í•  ìµœëŒ€ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
            """
            return await self.bulk_infrastructure_analysis_impl(status_filter, max_instances, ctx)
        
        @self.server.tool()
        async def emergency_recovery_plan(server_id: str, ctx: Context) -> str:
            """
            AI ê¸°ë°˜ ì‘ê¸‰ ë³µêµ¬ ê³„íš ìƒì„±
            
            Args:
                server_id: ì„œë²„ ID ë˜ëŠ” ì´ë¦„
                ctx: FastMCP Context
            """
            return await self.emergency_recovery_plan_impl(server_id, ctx)
        
        @self.server.tool()
        async def custom_question_analysis(server_id: str, question: str, ctx: Context) -> str:
            """
            ì‚¬ìš©ì ì •ì˜ ì§ˆë¬¸ìœ¼ë¡œ AI ë¶„ì„
            
            Args:
                server_id: ì„œë²„ ID ë˜ëŠ” ì´ë¦„
                question: ì‚¬ìš©ì ì§ˆë¬¸
                ctx: FastMCP Context
            """
            return await self.custom_question_analysis_impl(server_id, question, ctx)
        
        # ê¸°íƒ€ OpenStack ì„œë¹„ìŠ¤ íˆ´ë“¤
        @self.server.tool()
        def glance_list_images(public_only: bool = False) -> str:
            """ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ"""
            return self.glance_list_images_impl(public_only)
        
        @self.server.tool()
        def neutron_list_networks(external_only: bool = False) -> str:
            """ë„¤íŠ¸ì›Œí¬ ëª©ë¡ ì¡°íšŒ"""
            return self.neutron_list_networks_impl(external_only)
        
        @self.server.tool()
        def nova_list_flavors(public_only: bool = False) -> str:
            """Flavor ëª©ë¡ ì¡°íšŒ"""
            return self.nova_list_flavors_impl(public_only)
    
    # Nova êµ¬í˜„ ë©”ì„œë“œë“¤
    def nova_list_impl(self, detailed: bool = False, status: Optional[str] = None) -> str:
        """Nova ì„œë²„ ëª©ë¡ ì¡°íšŒ êµ¬í˜„"""
        try:
            filters = {}
            if status:
                filters["status"] = status.upper()
            
            servers = list(self.conn.compute.servers(detailed=detailed, **filters))
            
            if not servers:
                return "âŒ No servers found"
            
            result = []
            for server in servers:
                if detailed:
                    server_info = {
                        "id": server.id,
                        "name": server.name,
                        "status": server.status,
                        "flavor": server.flavor.get("original_name", server.flavor.get("id")),
                        "image": server.image.get("original_name", server.image.get("id")) if server.image else "N/A",
                        "created": str(server.created_at),
                        "updated": str(server.updated_at),
                        "addresses": server.addresses,
                        "power_state": getattr(server, 'power_state', 'N/A'),
                        "vm_state": getattr(server, 'vm_state', 'N/A')
                    }
                else:
                    server_info = {
                        "id": server.id,
                        "name": server.name,
                        "status": server.status
                    }
                result.append(server_info)
            
            return json.dumps(result, indent=2, ensure_ascii=False)
            
        except Exception as e:
            return f"âŒ Error listing servers: {str(e)}"
    
    def nova_show_impl(self, server_id: str) -> str:
        """ì„œë²„ ìƒì„¸ ì •ë³´ ì¡°íšŒ êµ¬í˜„"""
        try:
            server = self.conn.compute.get_server(server_id)
            if not server:
                return f"âŒ Server not found: {server_id}"
            
            server_info = {
                "id": server.id,
                "name": server.name,
                "status": server.status,
                "flavor": server.flavor,
                "image": server.image,
                "created": str(server.created_at),
                "updated": str(server.updated_at),
                "addresses": server.addresses,
                "metadata": server.metadata,
                "fault": server.fault,
                "power_state": getattr(server, 'power_state', 'N/A'),
                "task_state": getattr(server, 'task_state', 'N/A'),
                "vm_state": getattr(server, 'vm_state', 'N/A')
            }
            
            return json.dumps(server_info, indent=2, ensure_ascii=False, default=str)
            
        except Exception as e:
            return f"âŒ Error getting server details: {str(e)}"
    
    def nova_console_log_impl(self, server_id: str, length: int = 50) -> str:
        """ì½˜ì†” ë¡œê·¸ ì¡°íšŒ êµ¬í˜„"""
        try:
            server = self.conn.compute.get_server(server_id)
            if not server:
                return f"âŒ Server not found: {server_id}"
            
            console_log = self.conn.compute.get_server_console_output(server, length=length)
            
            if not console_log:
                return f"âŒ No console log available for {server.name}"
            
            return f"ğŸ“‹ Console log for {server.name} (last {length} lines):\n\n{console_log}"
            
        except Exception as e:
            return f"âŒ Error getting console log: {str(e)}"
    
    # AI ë¶„ì„ ë©”ì„œë“œë“¤
    def _extract_error_patterns(self, log_content: str) -> Dict[str, Any]:
        """ì—ëŸ¬ íŒ¨í„´ ì¶”ì¶œ"""
        if not log_content:
            return {"has_errors": False, "error_lines": []}
        
        error_indicators = [
            r'error', r'fail', r'panic', r'critical', r'fatal', r'emergency', 
            r'alert', r'warning', r'exception', r'segfault', r'oops', r'bug',
            r'cannot', r'unable', r'timeout', r'refused', r'denied'
        ]
        
        pattern = '|'.join(error_indicators)
        error_lines = []
        log_lines = log_content.split('\n')
        
        for i, line in enumerate(log_lines):
            if re.search(pattern, line, re.IGNORECASE):
                context = {
                    "line_number": i + 1,
                    "content": line.strip(),
                    "context_before": [l.strip() for l in log_lines[max(0, i-2):i] if l.strip()],
                    "context_after": [l.strip() for l in log_lines[i+1:min(len(log_lines), i+3)] if l.strip()]
                }
                error_lines.append(context)
        
        return {
            "has_errors": len(error_lines) > 0,
            "error_count": len(error_lines),
            "error_lines": error_lines[:15],
            "total_lines": len(log_lines)
        }
    
    async def analyze_instance_errors_impl(self, server_id: str, log_lines: int, ctx: Context) -> str:
        """ì¸ìŠ¤í„´ìŠ¤ ì—ëŸ¬ ë¶„ì„ êµ¬í˜„"""
        try:
            await ctx.info(f"ğŸ” Analyzing server {server_id}...")
            
            server = self.conn.compute.get_server(server_id)
            if not server:
                return f"âŒ Server not found: {server_id}"
            
            console_log = self.conn.compute.get_server_console_output(server, length=log_lines)
            if not console_log:
                return f"âŒ No console log available for server: {server.name}"
            
            error_analysis = self._extract_error_patterns(console_log)
            
            if not error_analysis["has_errors"]:
                return f"âœ… No obvious errors found in {server.name} console log. Instance appears healthy."
            
            await ctx.info(f"ğŸš¨ Found {error_analysis['error_count']} potential errors. Requesting AI analysis...")
            
            # AI ë¶„ì„ì„ ìœ„í•œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            analysis_prompt = f"""
ë‹¹ì‹ ì€ OpenStack ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¸ìŠ¤í„´ìŠ¤ì˜ ì½˜ì†” ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ì—ëŸ¬ ì§„ë‹¨ ë° í•´ê²°ì±…ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì¸ìŠ¤í„´ìŠ¤ ì •ë³´:**
- ID: {server.id}
- ì´ë¦„: {server.name}  
- ìƒíƒœ: {server.status}
- ìƒì„±ì¼: {server.created_at}
- Flavor: {json.dumps(server.flavor, indent=2) if server.flavor else "N/A"}
- Image: {json.dumps(server.image, indent=2) if server.image else "N/A"}

**ì—ëŸ¬ ë¶„ì„ ê²°ê³¼:**
- ì´ ì—ëŸ¬ ë¼ì¸: {error_analysis['error_count']}ê°œ
- ë¡œê·¸ ì´ ë¼ì¸: {error_analysis['total_lines']}ê°œ

**ì£¼ìš” ì—ëŸ¬ ë¼ì¸ë“¤:**
"""

            # ì—ëŸ¬ ìƒì„¸ ì •ë³´ ì¶”ê°€
            for i, error_line in enumerate(error_analysis["error_lines"][:10], 1):
                analysis_prompt += f"\nError {i} (Line {error_line['line_number']}):\n"
                analysis_prompt += f"  ë‚´ìš©: {error_line['content']}\n"
                if error_line['context_before']:
                    analysis_prompt += f"  ì´ì „: {' | '.join(error_line['context_before'][-2:])}\n"
                if error_line['context_after']:
                    analysis_prompt += f"  ì´í›„: {' | '.join(error_line['context_after'][:2])}\n"

            analysis_prompt += f"""

**ì „ì²´ ë¡œê·¸ (ë§ˆì§€ë§‰ ë¶€ë¶„):**
```
{console_log[-1500:] if len(console_log) > 1500 else console_log}
```

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ğŸ” ì—ëŸ¬ ì§„ë‹¨**: ë°œê²¬ëœ ì£¼ìš” ë¬¸ì œì ë“¤
2. **ğŸ¯ ê·¼ë³¸ ì›ì¸**: ê°€ëŠ¥ì„±ì´ ë†’ì€ ì›ì¸ ë¶„ì„  
3. **âš¡ ì¦‰ì‹œ í•´ê²°ì±…**: ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ OpenStack ëª…ë ¹ì–´ë“¤
4. **ğŸ”§ ìƒì„¸ í•´ê²° ë°©ë²•**: ë‹¨ê³„ë³„ ìƒì„¸ ê°€ì´ë“œ
5. **ğŸ›¡ï¸ ì˜ˆë°© ì¡°ì¹˜**: ì¬ë°œ ë°©ì§€ ë°©ë²•
6. **âš ï¸ ì£¼ì˜ì‚¬í•­**: í•´ê²° ê³¼ì •ì—ì„œ ì£¼ì˜í•  ì 

êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ OpenStack CLI ëª…ë ¹ì–´ë¥¼ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

            # LLMì—ê²Œ ë¶„ì„ ìš”ì²­
            ai_response = await ctx.sample(analysis_prompt)
            
            await ctx.info("âœ… AI analysis completed!")
            
            return f"""# ğŸ¤– AI ê¸°ë°˜ OpenStack ì¸ìŠ¤í„´ìŠ¤ ì—ëŸ¬ ë¶„ì„ ê²°ê³¼

## ì„œë²„ ì •ë³´
- **ID**: {server.id}
- **ì´ë¦„**: {server.name}
- **ìƒíƒœ**: {server.status}
- **ì—ëŸ¬ ìˆ˜**: {error_analysis['error_count']}ê°œ

## AI ë¶„ì„ ê²°ê³¼

{ai_response.content[0].text if ai_response.content else "AI ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

---
*ë¶„ì„ ì‹œê°„: {datetime.now().isoformat()}*
"""
            
        except Exception as e:
            await ctx.error(f"Error analyzing server {server_id}: {str(e)}")
            return f"âŒ Error analyzing server {server_id}: {str(e)}"
    
    async def bulk_infrastructure_analysis_impl(self, status_filter: Optional[str], max_instances: int, ctx: Context) -> str:
        """ì¸í”„ë¼ ì „ì²´ ë¶„ì„ êµ¬í˜„"""
        try:
            await ctx.info(f"ğŸ” Starting bulk infrastructure analysis...")
            
            filters = {}
            if status_filter:
                filters["status"] = status_filter.upper()
            
            servers = list(self.conn.compute.servers(**filters))[:max_instances]
            
            if not servers:
                return "âŒ No servers found for analysis"
            
            # ê° ì¸ìŠ¤í„´ìŠ¤ì˜ ê°„ë‹¨í•œ ë¶„ì„
            bulk_data = {
                "summary": {
                    "total_analyzed": len(servers),
                    "filter_applied": status_filter or "none",
                    "analysis_timestamp": datetime.now().isoformat()
                },
                "instances": []
            }
            
            problematic_instances = []
            
            for server in servers:
                try:
                    await ctx.info(f"Analyzing {server.name}...")
                    
                    console_log = self.conn.compute.get_server_console_output(server, length=100)
                    error_analysis = self._extract_error_patterns(console_log) if console_log else {"has_errors": False}
                    
                    instance_data = {
                        "id": server.id,
                        "name": server.name,
                        "status": server.status,
                        "has_errors": error_analysis.get("has_errors", False),
                        "error_count": error_analysis.get("error_count", 0),
                        "fault": server.fault,
                        "created": str(server.created_at),
                        "sample_errors": [
                            err["content"] for err in error_analysis.get("error_lines", [])[:3]
                        ] if error_analysis.get("has_errors") else []
                    }
                    
                    bulk_data["instances"].append(instance_data)
                    
                    if error_analysis.get("has_errors") or server.status == "ERROR":
                        problematic_instances.append(instance_data)
                    
                except Exception as e:
                    bulk_data["instances"].append({
                        "id": server.id,
                        "name": server.name,
                        "status": server.status,
                        "analysis_error": str(e)
                    })

            # AIì—ê²Œ ì „ì²´ ì¸í”„ë¼ ë¶„ì„ ìš”ì²­
            if problematic_instances:
                await ctx.info("ğŸ¤– Requesting AI analysis for infrastructure-level insights...")
                
                infrastructure_prompt = f"""
OpenStack í™˜ê²½ì˜ ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì¼ê´„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤. 
ì „ì²´ì ì¸ ì¸í”„ë¼ ê´€ì ì—ì„œ ë¬¸ì œì ê³¼ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê²°ê³¼ ìš”ì•½:**
- ì´ ë¶„ì„ ì¸ìŠ¤í„´ìŠ¤: {len(servers)}ê°œ
- ë¬¸ì œê°€ ìˆëŠ” ì¸ìŠ¤í„´ìŠ¤: {len(problematic_instances)}ê°œ
- í•„í„°: {status_filter or "ì—†ìŒ"}

**ë¬¸ì œê°€ ìˆëŠ” ì¸ìŠ¤í„´ìŠ¤ë“¤:**
{json.dumps(problematic_instances, indent=2, ensure_ascii=False)}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ğŸ—ï¸ ì¸í”„ë¼ ë ˆë²¨ ì´ìŠˆ**: ê³µí†µì ì¸ íŒ¨í„´ì´ë‚˜ ì‹œìŠ¤í…œ ë¬¸ì œ
2. **ğŸ“Š ìš°ì„ ìˆœìœ„**: ì–´ë–¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€
3. **ğŸ”„ ìë™í™” ì œì•ˆ**: ë°˜ë³µì ì¸ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìë™í™” ë°©ì•ˆ
4. **ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ê°•í™”**: ì¶”ê°€ë¡œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  ë©”íŠ¸ë¦­ë“¤
5. **ğŸš¨ ì—ìŠ¤ì»¬ë ˆì´ì…˜**: ìƒìœ„ íŒ€ì— ë³´ê³ í•´ì•¼ í•  ì‚¬í•­ë“¤

ì‹¤í–‰ ê°€ëŠ¥í•œ OpenStack ëª…ë ¹ì–´ì™€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

                ai_response = await ctx.sample(infrastructure_prompt)
                ai_analysis = ai_response.content[0].text if ai_response.content else "AI ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                ai_analysis = "âœ… ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ê°€ ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤. íŠ¹ë³„í•œ ì¡°ì¹˜ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

            await ctx.info("âœ… Bulk analysis completed!")
            
            return f"""# ğŸ—ï¸ OpenStack ì¸í”„ë¼ ì „ì²´ ë¶„ì„ ê²°ê³¼

## ğŸ“Š ë¶„ì„ ìš”ì•½
- **ì´ ì¸ìŠ¤í„´ìŠ¤**: {len(servers)}ê°œ
- **ë¬¸ì œ ì¸ìŠ¤í„´ìŠ¤**: {len(problematic_instances)}ê°œ
- **ì •ìƒ ì¸ìŠ¤í„´ìŠ¤**: {len(servers) - len(problematic_instances)}ê°œ

## ğŸ¤– AI ì¸í”„ë¼ ë¶„ì„

{ai_analysis}

## ğŸ“‹ ìƒì„¸ ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡

{json.dumps(bulk_data, indent=2, ensure_ascii=False)}

---
*ë¶„ì„ ì‹œê°„: {datetime.now().isoformat()}*
"""
            
        except Exception as e:
            await ctx.error(f"Error in bulk analysis: {str(e)}")
            return f"âŒ Error in bulk analysis: {str(e)}"
    
    async def emergency_recovery_plan_impl(self, server_id: str, ctx: Context) -> str:
        """ì‘ê¸‰ ë³µêµ¬ ê³„íš ìƒì„± êµ¬í˜„"""
        try:
            await ctx.info(f"ğŸš¨ Creating emergency recovery plan for {server_id}...")
            
            server = self.conn.compute.get_server(server_id)
            if not server:
                return f"âŒ Server not found: {server_id}"
            
            console_log = self.conn.compute.get_server_console_output(server, length=300)
            error_analysis = self._extract_error_patterns(console_log) if console_log else {"has_errors": False}
            
            recovery_prompt = f"""
OpenStack ì¸ìŠ¤í„´ìŠ¤ì— ì‹¬ê°í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‘ê¸‰ ë³µêµ¬ ì ˆì°¨ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì¸ìŠ¤í„´ìŠ¤ ì •ë³´:**
- ID: {server.id}
- ì´ë¦„: {server.name}
- í˜„ì¬ ìƒíƒœ: {server.status}
- Power State: {getattr(server, 'power_state', 'N/A')}
- VM State: {getattr(server, 'vm_state', 'N/A')}
- Task State: {getattr(server, 'task_state', 'N/A')}
- Fault: {server.fault if server.fault else "ì—†ìŒ"}

**ì—ëŸ¬ ë¶„ì„:**
- ì—ëŸ¬ ë°œê²¬: {"ì˜ˆ" if error_analysis.get("has_errors") else "ì•„ë‹ˆì˜¤"}
- ì—ëŸ¬ ìˆ˜: {error_analysis.get("error_count", 0)}ê°œ

**ìµœê·¼ ë¡œê·¸ (ë§ˆì§€ë§‰ 500ì):**
```
{console_log[-500:] if console_log else "ë¡œê·¸ ì—†ìŒ"}
```

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ê¸‰ ë³µêµ¬ ê³„íšì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **ğŸš¨ ì¦‰ì‹œ ì‹¤í–‰ í•­ëª©** (5ë¶„ ì´ë‚´)
2. **âš¡ ë‹¨ê¸° ë³µêµ¬ ì ˆì°¨** (30ë¶„ ì´ë‚´)  
3. **ğŸ”§ ì¥ê¸° í•´ê²° ë°©ì•ˆ** (1ì‹œê°„ ì´ë‚´)
4. **ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸** (ê° ë‹¨ê³„ë³„ í™•ì¸ì‚¬í•­)
5. **ğŸ†˜ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê¸°ì¤€** (ì–¸ì œ ìƒìœ„íŒ€ì— ë³´ê³ í• ì§€)
6. **ğŸ“ ë¹„ìƒ ì—°ë½ì²˜** (í•„ìš”í•œ íŒ€ë“¤)

ëª¨ë“  ëª…ë ¹ì–´ëŠ” OpenStack CLI ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

            ai_response = await ctx.sample(recovery_prompt)
            await ctx.info("âœ… Emergency recovery plan generated!")
            
            return f"""# ğŸš¨ AI ê¸°ë°˜ ì‘ê¸‰ ë³µêµ¬ ê³„íš

## ì¸ìŠ¤í„´ìŠ¤ ì •ë³´
- **ì„œë²„**: {server.name} ({server.id})
- **í˜„ì¬ ìƒíƒœ**: {server.status}
- **ìƒì„± ì‹œê°„**: {datetime.now().isoformat()}

## ğŸ¤– AI ìƒì„± ë³µêµ¬ ê³„íš

{ai_response.content[0].text if ai_response.content else "ë³µêµ¬ ê³„íšì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

## âš ï¸ ì¤‘ìš” ì•ˆë‚´
- ë³µêµ¬ ì‘ì—… ì „ì— ë°˜ë“œì‹œ ìŠ¤ëƒ…ìƒ· ìƒì„±ì„ ê³ ë ¤í•˜ì„¸ìš”
- ê° ë‹¨ê³„ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
- ë¬¸ì œê°€ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ ì¦‰ì‹œ ì—ìŠ¤ì»¬ë ˆì´ì…˜í•˜ì„¸ìš”

---
*ê³„íš ìƒì„± ì‹œê°„: {datetime.now().isoformat()}*
"""
            
        except Exception as e:
            await ctx.error(f"Error creating recovery plan: {str(e)}")
            return f"âŒ Error creating recovery plan: {str(e)}"
    
    async def custom_question_analysis_impl(self, server_id: str, question: str, ctx: Context) -> str:
        """ì‚¬ìš©ì ì •ì˜ ì§ˆë¬¸ ë¶„ì„ êµ¬í˜„"""
        try:
            await ctx.info(f"ğŸ¤” Processing custom question about {server_id}...")
            
            server = self.conn.compute.get_server(server_id)
            if not server:
                return f"âŒ Server not found: {server_id}"
            
            console_log = self.conn.compute.get_server_console_output(server, length=250)
            
            custom_prompt = f"""
OpenStack ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì¸ìŠ¤í„´ìŠ¤ ì •ë³´:**
- ID: {server.id}
- ì´ë¦„: {server.name}
- ìƒíƒœ: {server.status}
- Flavor: {json.dumps(server.flavor, indent=2) if server.flavor else "N/A"}

**ì‚¬ìš©ì ì§ˆë¬¸:**
{question}

**ê´€ë ¨ ì½˜ì†” ë¡œê·¸:**
```
{console_log if console_log else "ë¡œê·¸ ì—†ìŒ"}
```

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ OpenStack ëª…ë ¹ì–´ë‚˜ í•´ê²° ë°©ë²•ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""

            ai_response = await ctx.sample(custom_prompt)
            await ctx.info("âœ… Custom analysis completed!")
            
            return f"""# ğŸ¤” ì‚¬ìš©ì ì •ì˜ ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼

## ì§ˆë¬¸
> {question}

## ì¸ìŠ¤í„´ìŠ¤ ì •ë³´
- **ì„œë²„**: {server.name} ({server.id})
- **ìƒíƒœ**: {server.status}

## ğŸ¤– AI ë‹µë³€

{ai_response.content[0].text if ai_response.content else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

---
*ë¶„ì„ ì‹œê°„: {datetime.now().isoformat()}*
"""
            
        except Exception as e:
            await ctx.error(f"Error processing custom question: {str(e)}")
            return f"âŒ Error processing question: {str(e)}"
    
    # ê¸°íƒ€ OpenStack ì„œë¹„ìŠ¤ êµ¬í˜„ ë©”ì„œë“œë“¤
    def glance_list_images_impl(self, public_only: bool) -> str:
        """ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ êµ¬í˜„"""
        try:
            filters = {}
            if public_only:
                filters["visibility"] = "public"
            
            images = list(self.conn.image.images(**filters))
            
            if not images:
                return "âŒ No images found"
            
            result = []
            for image in images:
                image_info = {
                    "id": image.id,
                    "name": image.name,
                    "status": image.status,
                    "visibility": image.visibility,
                    "size": image.size,
                    "created": str(image.created_at),
                    "updated": str(image.updated_at)
                }
                result.append(image_info)
            
            return json.dumps(result, indent=2, ensure_ascii=False)
            
        except Exception as e:
            return f"âŒ Error listing images: {str(e)}"
    
    def neutron_list_networks_impl(self, external_only: bool) -> str:
        """ë„¤íŠ¸ì›Œí¬ ëª©ë¡ ì¡°íšŒ êµ¬í˜„"""
        try:
            filters = {}
            if external_only:
                filters["router:external"] = True
            
            networks = list(self.conn.network.networks(**filters))
            
            if not networks:
                return "âŒ No networks found"
            
            result = []
            for network in networks:
                network_info = {
                    "id": network.id,
                    "name": network.name,
                    "status": network.status,
                    "admin_state_up": network.is_admin_state_up,
                    "external": network.is_router_external,
                    "shared": network.is_shared,
                    "subnets": network.subnet_ids
                }
                result.append(network_info)
            
            return json.dumps(result, indent=2, ensure_ascii=False)
            
        except Exception as e:
            return f"âŒ Error listing networks: {str(e)}"
    
    def nova_list_flavors_impl(self, public_only: bool) -> str:
        """Flavor ëª©ë¡ ì¡°íšŒ êµ¬í˜„"""
        try:
            filters = {}
            if public_only:
                filters["is_public"] = True
            
            flavors = list(self.conn.compute.flavors(**filters))
            
            if not flavors:
                return "âŒ No flavors found"
            
            result = []
            for flavor in flavors:
                flavor_info = {
                    "id": flavor.id,
                    "name": flavor.name,
                    "vcpus": flavor.vcpus,
                    "ram": flavor.ram,
                    "disk": flavor.disk,
                    "ephemeral": flavor.ephemeral,
                    "swap": flavor.swap,
                    "is_public": flavor.is_public
                }
                result.append(flavor_info)
            
            return json.dumps(result, indent=2, ensure_ascii=False)
            
        except Exception as e:
            return f"âŒ Error listing flavors: {str(e)}"
    
    def run(self):
        """MCP ì„œë²„ ì‹¤í–‰"""
        print(f"ğŸš€ Starting OpenStack MCP Server...")
        self.server.run()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # OpenStack MCP ì„œë²„ ìƒì„± ë° ì‹¤í–‰
    openstack_mcp = OpenStackMCP(name="openstack-ai-analyzer")
    openstack_mcp.run()